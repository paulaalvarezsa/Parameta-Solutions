# Parameta Coding Test – Data Science Role

This repository contains my solutions to the two technical challenges provided by Parameta Solutions as part of the interview process for the data science position.

---

## Project Structure

```
parameta-coding-test/
├── rates_test/                     # Problem 1: FX Rate Conversion
│   ├── data/                       # Input data files
│   ├── results/                    # Output CSV generated by the script
│   └── scripts/                    # Python script for the problem
├── stdev_test/                     # Problem 2: Rolling Standard Deviation
│   ├── data/                       # Input data file
│   ├── results/                    # Output CSV generated by the script
│   └── scripts/                    # Python script for the problem
├── requirements.txt                # Python dependencies
└── README.md                       # This file
```

---

## Problem 1 – FX Rate Conversion

This script processes hourly price data for a set of FX currency pairs and calculates a `final_price` for each one.

The logic depends on whether conversion is required for that currency pair:

- If no conversion is needed, the final price is the original price.
- If conversion is needed:
  - The script looks for the most recent `spot_mid_rate` available within the hour *before* the price timestamp.
  - It then applies the formula:
    ```
    final_price = (price / conversion_factor) + spot_mid_rate
    ```
- If there's no spot rate available in that lookback window, the result is set to `NaN`.

### How to run:

```bash
python rates_test/scripts/process_rates.py \
  --ccy rates_test/data/rates_ccy_data.csv \
  --price rates_test/data/rates_price_data.parq.gzip \
  --spot rates_test/data/rates_spot_rate_data.parq.gzip \
  --out rates_test/results/rates_converted.csv
```

---

## Problem 2 – Rolling Standard Deviation

This script calculates rolling standard deviations for `bid`, `mid`, and `ask` prices for each security ID. The standard deviation is based on the previous 20 *consecutive* hourly price points before each snap time.

It covers the range from:
```
2021-11-20 00:00:00 to 2021-11-23 09:00:00
```

Key points:
- Only includes snap times where there are exactly 20 uninterrupted hourly values before it.
- If there's a gap in the data, that time point is skipped.

### How to run:

```bash
python stdev_test/scripts/compute_stdev.py \
  --input stdev_test/data/stdev_price_data.parq.gzip \
  --output stdev_test/results/rolling_stdev.csv
```

---

## Installation

To install the required Python libraries:

```bash
pip install -r requirements.txt
```

Dependencies:
- pandas
- numpy
- pyarrow

---

## Notes

- Both scripts are class-based, structured for clarity, and designed to be executed via command line.
- They use pandas and numpy for efficient data manipulation.
- The code assumes that input files are already decompressed and placed in the appropriate `data/` folders.

---

## Author

Prepared by Paula as part of the technical interview with Parameta Solutions.

